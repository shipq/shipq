package codegen

import (
	"bytes"
	"fmt"
	"go/format"
	"sort"
	"strings"

	"github.com/portsql/portsql/src/ddl"
	"github.com/portsql/portsql/src/migrate"
	"github.com/portsql/portsql/src/query"
)

// CompiledQuery holds the compiled information for a single query.
type CompiledQuery struct {
	Name       string
	SQL        string
	Params     []ParamInfo
	Results    []ResultInfo
	ReturnType string // "one", "many", or "exec"
}

// ParamInfo describes a query parameter.
type ParamInfo struct {
	Name   string
	GoType string
}

// ResultInfo describes a result column.
type ResultInfo struct {
	Name   string
	GoType string
	// NestedFields holds the fields for JSON aggregation results.
	// When non-empty, this result is a nested type (slice of objects).
	NestedFields []ResultInfo
}

// GenerateSharedTypes generates types.go with shared param/result structs for all dialects.
// This includes both user-defined query types and CRUD types.
func GenerateSharedTypes(queries []CompiledQuery, crudPlan *migrate.MigrationPlan, packageName string, tableOpts map[string]CRUDOptions) ([]byte, error) {
	// Validate queries for duplicate field names before generating code
	for _, q := range queries {
		if err := validateNoDuplicateFields(q); err != nil {
			return nil, err
		}
	}

	var buf bytes.Buffer

	// Collect imports from user-defined queries
	imports := make(map[string]bool)
	for _, q := range queries {
		for _, p := range q.Params {
			if imp := goTypeImport(p.GoType); imp != "" {
				imports[imp] = true
			}
		}
		collectImportsFromResults(q.Results, imports)
	}

	// Collect imports from CRUD tables
	if crudPlan != nil {
		for _, table := range crudPlan.Schema.Tables {
			for _, col := range table.Columns {
				mapping := MapColumnType(col)
				if mapping.NeedsImport != "" {
					imports[mapping.NeedsImport] = true
				}
			}
		}
	}

	// Sort queries by name for deterministic output
	sort.Slice(queries, func(i, j int) bool {
		return queries[i].Name < queries[j].Name
	})

	// Write header
	buf.WriteString("// Code generated by portsql. DO NOT EDIT.\n")
	buf.WriteString(fmt.Sprintf("package %s\n\n", packageName))

	// Write imports if needed
	if len(imports) > 0 {
		buf.WriteString("import (\n")
		importList := make([]string, 0, len(imports))
		for imp := range imports {
			importList = append(importList, imp)
		}
		sort.Strings(importList)
		for _, imp := range importList {
			buf.WriteString(fmt.Sprintf("\t%q\n", imp))
		}
		buf.WriteString(")\n\n")
	}

	// Generate user-defined query types (params and results only, no SQL)
	if len(queries) > 0 {
		buf.WriteString("// ========== User-Defined Query Types ==========\n\n")
		for _, q := range queries {
			// Params struct (if any)
			if len(q.Params) > 0 {
				buf.WriteString(fmt.Sprintf("// %sParams contains the parameters for %s.\n", q.Name, q.Name))
				buf.WriteString(fmt.Sprintf("type %sParams struct {\n", q.Name))
				for _, p := range q.Params {
					fieldName := toPascalCase(p.Name)
					buf.WriteString(fmt.Sprintf("\t%s %s\n", fieldName, p.GoType))
				}
				buf.WriteString("}\n\n")
			}

			// Result struct (if any)
			if len(q.Results) > 0 {
				buf.WriteString(fmt.Sprintf("// %sResult contains a single result row for %s.\n", q.Name, q.Name))
				buf.WriteString(fmt.Sprintf("type %sResult struct {\n", q.Name))
				for _, r := range q.Results {
					fieldName := toPascalCase(r.Name)
					goType := r.GoType
					// Handle nested types (JSON aggregation)
					if len(r.NestedFields) > 0 {
						nestedTypeName := q.Name + fieldName + "Item"
						goType = "[]" + nestedTypeName
					}
					buf.WriteString(fmt.Sprintf("\t%s %s\n", fieldName, goType))
				}
				buf.WriteString("}\n\n")

				// Generate nested structs for JSON aggregation fields
				generateNestedStructs(&buf, q.Name, "", q.Results)
			}
		}
	}

	// Generate CRUD types for each table
	if crudPlan != nil && len(crudPlan.Schema.Tables) > 0 {
		// Sort table names for deterministic output
		tableNames := make([]string, 0, len(crudPlan.Schema.Tables))
		for name := range crudPlan.Schema.Tables {
			tableNames = append(tableNames, name)
		}
		sort.Strings(tableNames)

		for _, tableName := range tableNames {
			table := crudPlan.Schema.Tables[tableName]
			opts := CRUDOptions{}
			if tableOpts != nil {
				opts = tableOpts[tableName]
			}

			analysis := AnalyzeTable(table)
			singular := toSingular(table.Name)
			singularPascal := toPascalCase(singular)

			buf.WriteString(fmt.Sprintf("// ========== %s CRUD Types ==========\n\n", toPascalCase(table.Name)))

			// --- Get ---
			writeGetTypes(&buf, table, analysis, singularPascal, opts)

			// --- List ---
			writeListTypes(&buf, table, analysis, singularPascal, opts)

			// --- Insert ---
			writeInsertTypes(&buf, table, analysis, singularPascal, opts)

			// --- Update ---
			writeUpdateTypes(&buf, table, analysis, singularPascal, opts)

			// --- Delete ---
			writeDeleteTypes(&buf, table, analysis, singularPascal, opts)

			// --- HardDelete (only if table has deleted_at) ---
			if analysis.HasDeletedAt {
				writeHardDeleteTypes(&buf, table, analysis, singularPascal, opts)
			}
		}
	}

	// Format the code
	formatted, err := format.Source(buf.Bytes())
	if err != nil {
		return buf.Bytes(), fmt.Errorf("failed to format generated code: %w", err)
	}

	return formatted, nil
}

// =============================================================================
// CRUD Type Helpers (for GenerateSharedTypes)
// =============================================================================

// writeGetTypes writes the Get param and result types
func writeGetTypes(buf *bytes.Buffer, table ddl.Table, analysis TableAnalysis, singularPascal string, opts CRUDOptions) {
	// Get params - use public_id if available, otherwise id
	buf.WriteString(fmt.Sprintf("// --- Get ---\n\n"))
	buf.WriteString(fmt.Sprintf("// Get%sParams contains parameters for fetching a single %s.\n", singularPascal, toSingular(table.Name)))
	buf.WriteString(fmt.Sprintf("type Get%sParams struct {\n", singularPascal))

	if analysis.HasPublicID {
		buf.WriteString("\tPublicID string\n")
	} else {
		buf.WriteString("\tID int64\n")
	}

	// Add scope column if configured
	if opts.ScopeColumn != "" {
		scopeCol := findColumn(table, opts.ScopeColumn)
		if scopeCol != nil {
			mapping := MapColumnType(*scopeCol)
			buf.WriteString(fmt.Sprintf("\t%s %s\n", toPascalCase(opts.ScopeColumn), mapping.GoType))
		}
	}

	buf.WriteString("}\n\n")

	// Get result - all result columns
	buf.WriteString(fmt.Sprintf("// Get%sResult contains the result of fetching a single %s.\n", singularPascal, toSingular(table.Name)))
	buf.WriteString(fmt.Sprintf("type Get%sResult struct {\n", singularPascal))
	for _, col := range analysis.ResultColumns {
		mapping := MapColumnType(col)
		buf.WriteString(fmt.Sprintf("\t%s %s\n", toPascalCase(col.Name), mapping.GoType))
	}
	buf.WriteString("}\n\n")
}

// writeListTypes writes the List param and result types
func writeListTypes(buf *bytes.Buffer, table ddl.Table, analysis TableAnalysis, singularPascal string, opts CRUDOptions) {
	pluralPascal := toPascalCase(table.Name)

	buf.WriteString(fmt.Sprintf("// --- List ---\n\n"))
	buf.WriteString(fmt.Sprintf("// List%sParams contains parameters for listing %s.\n", pluralPascal, table.Name))
	buf.WriteString(fmt.Sprintf("type List%sParams struct {\n", pluralPascal))

	// Add scope column if configured
	if opts.ScopeColumn != "" {
		scopeCol := findColumn(table, opts.ScopeColumn)
		if scopeCol != nil {
			mapping := MapColumnType(*scopeCol)
			buf.WriteString(fmt.Sprintf("\t%s %s\n", toPascalCase(opts.ScopeColumn), mapping.GoType))
		}
	}

	buf.WriteString("\tLimit  int\n")
	buf.WriteString("\tOffset int\n")
	buf.WriteString("}\n\n")

	// List result - result columns excluding updated_at for brevity
	buf.WriteString(fmt.Sprintf("// List%sResult contains a single item from a list of %s.\n", pluralPascal, table.Name))
	buf.WriteString(fmt.Sprintf("type List%sResult struct {\n", pluralPascal))
	for _, col := range analysis.ResultColumns {
		// Optionally exclude updated_at from list results for brevity
		if col.Name == "updated_at" {
			continue
		}
		mapping := MapColumnType(col)
		buf.WriteString(fmt.Sprintf("\t%s %s\n", toPascalCase(col.Name), mapping.GoType))
	}
	buf.WriteString("}\n\n")
}

// writeInsertTypes writes the Insert param type
func writeInsertTypes(buf *bytes.Buffer, table ddl.Table, analysis TableAnalysis, singularPascal string, opts CRUDOptions) {
	buf.WriteString(fmt.Sprintf("// --- Insert ---\n\n"))
	buf.WriteString(fmt.Sprintf("// Insert%sParams contains parameters for inserting a new %s.\n", singularPascal, toSingular(table.Name)))
	buf.WriteString(fmt.Sprintf("type Insert%sParams struct {\n", singularPascal))

	// Add scope column if configured (user provides it on insert)
	if opts.ScopeColumn != "" {
		scopeCol := findColumn(table, opts.ScopeColumn)
		if scopeCol != nil {
			mapping := MapColumnType(*scopeCol)
			buf.WriteString(fmt.Sprintf("\t%s %s\n", toPascalCase(opts.ScopeColumn), mapping.GoType))
		}
	}

	// Only user-provided columns (not auto-filled)
	for _, col := range analysis.UserColumns {
		// Skip scope column if already added
		if opts.ScopeColumn != "" && col.Name == opts.ScopeColumn {
			continue
		}
		mapping := MapColumnType(col)
		buf.WriteString(fmt.Sprintf("\t%s %s\n", toPascalCase(col.Name), mapping.GoType))
	}
	buf.WriteString("}\n\n")
}

// writeUpdateTypes writes the Update param type
func writeUpdateTypes(buf *bytes.Buffer, table ddl.Table, analysis TableAnalysis, singularPascal string, opts CRUDOptions) {
	buf.WriteString(fmt.Sprintf("// --- Update ---\n\n"))
	buf.WriteString(fmt.Sprintf("// Update%sParams contains parameters for updating a %s.\n", singularPascal, toSingular(table.Name)))
	buf.WriteString(fmt.Sprintf("type Update%sParams struct {\n", singularPascal))

	// Primary identifier for WHERE clause
	if analysis.HasPublicID {
		buf.WriteString("\tPublicID string\n")
	} else {
		buf.WriteString("\tID int64\n")
	}

	// Add scope column if configured
	if opts.ScopeColumn != "" {
		scopeCol := findColumn(table, opts.ScopeColumn)
		if scopeCol != nil {
			mapping := MapColumnType(*scopeCol)
			buf.WriteString(fmt.Sprintf("\t%s %s\n", toPascalCase(opts.ScopeColumn), mapping.GoType))
		}
	}

	// User-provided columns
	for _, col := range analysis.UserColumns {
		// Skip scope column if already added
		if opts.ScopeColumn != "" && col.Name == opts.ScopeColumn {
			continue
		}
		mapping := MapColumnType(col)
		buf.WriteString(fmt.Sprintf("\t%s %s\n", toPascalCase(col.Name), mapping.GoType))
	}
	buf.WriteString("}\n\n")
}

// writeDeleteTypes writes the Delete param type
func writeDeleteTypes(buf *bytes.Buffer, table ddl.Table, analysis TableAnalysis, singularPascal string, opts CRUDOptions) {
	buf.WriteString(fmt.Sprintf("// --- Delete ---\n\n"))
	buf.WriteString(fmt.Sprintf("// Delete%sParams contains parameters for deleting a %s.\n", singularPascal, toSingular(table.Name)))
	buf.WriteString(fmt.Sprintf("type Delete%sParams struct {\n", singularPascal))
	if analysis.HasPublicID {
		buf.WriteString("\tPublicID string\n")
	} else {
		buf.WriteString("\tID int64\n")
	}
	// Add scope column if configured
	if opts.ScopeColumn != "" {
		scopeCol := findColumn(table, opts.ScopeColumn)
		if scopeCol != nil {
			mapping := MapColumnType(*scopeCol)
			buf.WriteString(fmt.Sprintf("\t%s %s\n", toPascalCase(opts.ScopeColumn), mapping.GoType))
		}
	}
	buf.WriteString("}\n\n")
}

// writeHardDeleteTypes writes the HardDelete param type
func writeHardDeleteTypes(buf *bytes.Buffer, table ddl.Table, analysis TableAnalysis, singularPascal string, opts CRUDOptions) {
	buf.WriteString(fmt.Sprintf("// --- HardDelete ---\n\n"))
	buf.WriteString(fmt.Sprintf("// HardDelete%sParams contains parameters for permanently deleting a %s.\n", singularPascal, toSingular(table.Name)))
	buf.WriteString(fmt.Sprintf("type HardDelete%sParams struct {\n", singularPascal))
	if analysis.HasPublicID {
		buf.WriteString("\tPublicID string\n")
	} else {
		buf.WriteString("\tID int64\n")
	}
	// Add scope column if configured
	if opts.ScopeColumn != "" {
		scopeCol := findColumn(table, opts.ScopeColumn)
		if scopeCol != nil {
			mapping := MapColumnType(*scopeCol)
			buf.WriteString(fmt.Sprintf("\t%s %s\n", toPascalCase(opts.ScopeColumn), mapping.GoType))
		}
	}
	buf.WriteString("}\n\n")
}

// findColumn finds a column by name in a table
func findColumn(table ddl.Table, name string) *ddl.ColumnDefinition {
	for _, col := range table.Columns {
		if col.Name == name {
			return &col
		}
	}
	return nil
}

// collectImportsFromResults recursively collects imports from results including nested fields.
func collectImportsFromResults(results []ResultInfo, imports map[string]bool) {
	for _, r := range results {
		if imp := goTypeImport(r.GoType); imp != "" {
			imports[imp] = true
		}
		// Recursively check nested fields
		if len(r.NestedFields) > 0 {
			collectImportsFromResults(r.NestedFields, imports)
		}
	}
}

// generateNestedStructs generates struct types for JSON aggregation fields.
// It handles multi-level nesting by recursively processing NestedFields.
func generateNestedStructs(buf *bytes.Buffer, queryName, parentPath string, results []ResultInfo) {
	for _, r := range results {
		if len(r.NestedFields) == 0 {
			continue
		}

		fieldName := toPascalCase(r.Name)
		// Build the current path for this type
		var currentPath string
		if parentPath == "" {
			currentPath = fieldName
		} else {
			currentPath = parentPath + fieldName
		}
		typeName := queryName + currentPath + "Item"

		buf.WriteString(fmt.Sprintf("// %s represents a single item in the %s JSON array.\n", typeName, r.Name))
		buf.WriteString(fmt.Sprintf("type %s struct {\n", typeName))
		for _, nested := range r.NestedFields {
			nestedFieldName := toPascalCase(nested.Name)
			goType := nested.GoType
			// Handle deeply nested types - use the full path
			if len(nested.NestedFields) > 0 {
				nestedTypeName := queryName + currentPath + nestedFieldName + "Item"
				goType = "[]" + nestedTypeName
			}
			buf.WriteString(fmt.Sprintf("\t%s %s\n", nestedFieldName, goType))
		}
		buf.WriteString("}\n\n")

		// Recursively generate structs for deeply nested fields
		generateNestedStructs(buf, queryName, currentPath, r.NestedFields)
	}
}

// validateNoDuplicateFields checks that a query's result columns don't have duplicate
// field names after PascalCase conversion. This would generate invalid Go code.
func validateNoDuplicateFields(q CompiledQuery) error {
	// Check result fields
	resultFields := make(map[string]string) // PascalCase name -> original name
	for _, r := range q.Results {
		fieldName := toPascalCase(r.Name)
		if existingName, exists := resultFields[fieldName]; exists {
			return fmt.Errorf(
				"query %q has duplicate result field %q (from columns %q and %q). "+
					"Use SelectAs() to give one of them an alias",
				q.Name, fieldName, existingName, r.Name,
			)
		}
		resultFields[fieldName] = r.Name
	}

	// Check param fields
	paramFields := make(map[string]string)
	for _, p := range q.Params {
		fieldName := toPascalCase(p.Name)
		if existingName, exists := paramFields[fieldName]; exists {
			return fmt.Errorf(
				"query %q has duplicate parameter field %q (from params %q and %q)",
				q.Name, fieldName, existingName, p.Name,
			)
		}
		paramFields[fieldName] = p.Name
	}

	return nil
}

// goTypeImport returns the import path needed for a Go type, or empty string if none.
func goTypeImport(goType string) string {
	if strings.Contains(goType, "time.Time") {
		return "time"
	}
	if strings.Contains(goType, "json.RawMessage") {
		return "encoding/json"
	}
	return ""
}

// formatSQLString formats SQL as a Go string literal.
func formatSQLString(sql string) string {
	// Use backticks for multi-line or complex SQL
	if strings.Contains(sql, "\n") || strings.Contains(sql, `"`) {
		// Escape backticks by using string concatenation
		if strings.Contains(sql, "`") {
			// Fall back to double-quoted string with escaping
			escaped := strings.ReplaceAll(sql, `\`, `\\`)
			escaped = strings.ReplaceAll(escaped, `"`, `\"`)
			escaped = strings.ReplaceAll(escaped, "\n", `\n`)
			return fmt.Sprintf(`"%s"`, escaped)
		}
		return fmt.Sprintf("`%s`", sql)
	}
	// Simple single-line SQL
	return fmt.Sprintf("`%s`", sql)
}

// ExtractResultInfo extracts result column information from a SELECT query AST.
func ExtractResultInfo(ast *query.AST) []ResultInfo {
	if ast.Kind != query.SelectQuery {
		return nil
	}

	var results []ResultInfo
	for _, sel := range ast.SelectCols {
		name := ""
		goType := "interface{}"
		var nestedFields []ResultInfo

		// Determine name
		if sel.Alias != "" {
			name = sel.Alias
		} else {
			// Try to extract from expression
			switch e := sel.Expr.(type) {
			case query.ColumnExpr:
				name = e.Column.ColumnName()
				goType = e.Column.GoType()
			case query.AggregateExpr:
				// Aggregates need an alias or we use the function name
				if sel.Alias == "" {
					name = strings.ToLower(string(e.Func))
				}
				// Determine type based on aggregate
				switch e.Func {
				case query.AggCount:
					goType = "int64"
				case query.AggSum, query.AggAvg:
					// Type depends on the argument
					if col, ok := e.Arg.(query.ColumnExpr); ok {
						goType = col.Column.GoType()
					} else {
						goType = "float64"
					}
				case query.AggMin, query.AggMax:
					if col, ok := e.Arg.(query.ColumnExpr); ok {
						goType = col.Column.GoType()
					}
				}
			case query.JSONAggExpr:
				// JSON aggregation - extract nested column types
				name = e.FieldName
				// Extract nested fields from the columns
				for _, col := range e.Columns {
					nestedFields = append(nestedFields, ResultInfo{
						Name:   col.ColumnName(),
						GoType: col.GoType(),
					})
				}
				// GoType will be set by GenerateQueriesPackage based on the nested type name
				goType = "" // Marker - will be replaced with []TypeName
			default:
				// For other expressions, need an alias
				continue
			}
		}

		// Get Go type from column expression
		if goType == "interface{}" {
			switch e := sel.Expr.(type) {
			case query.ColumnExpr:
				goType = e.Column.GoType()
			}
		}

		// Handle JSONAggExpr when it has an alias
		if goType == "interface{}" || goType == "" {
			switch e := sel.Expr.(type) {
			case query.JSONAggExpr:
				for _, col := range e.Columns {
					nestedFields = append(nestedFields, ResultInfo{
						Name:   col.ColumnName(),
						GoType: col.GoType(),
					})
				}
				goType = "" // Marker - will be replaced with []TypeName
			}
		}

		if name != "" {
			results = append(results, ResultInfo{
				Name:         name,
				GoType:       goType,
				NestedFields: nestedFields,
			})
		}
	}

	return results
}

// ExtractParamInfo extracts parameter information from the AST by walking
// all expressions and collecting ParamExpr instances.
func ExtractParamInfo(ast *query.AST) []ParamInfo {
	var params []ParamInfo
	seen := make(map[string]bool)

	// Helper to collect params from an expression
	var collectFromExpr func(expr query.Expr)
	collectFromExpr = func(expr query.Expr) {
		if expr == nil {
			return
		}

		switch e := expr.(type) {
		case query.ParamExpr:
			if !seen[e.Name] {
				params = append(params, ParamInfo{
					Name:   e.Name,
					GoType: e.GoType,
				})
				seen[e.Name] = true
			}
		case query.BinaryExpr:
			collectFromExpr(e.Left)
			collectFromExpr(e.Right)
		case query.UnaryExpr:
			collectFromExpr(e.Expr)
		case query.FuncExpr:
			for _, arg := range e.Args {
				collectFromExpr(arg)
			}
		case query.ListExpr:
			for _, val := range e.Values {
				collectFromExpr(val)
			}
		case query.AggregateExpr:
			collectFromExpr(e.Arg)
		case query.SubqueryExpr:
			collectFromAST(e.Query, &params, seen)
		case query.ExistsExpr:
			collectFromAST(e.Subquery, &params, seen)
		}
	}

	collectFromAST(ast, &params, seen)
	return params
}

// collectFromAST walks an AST and collects all params.
func collectFromAST(ast *query.AST, params *[]ParamInfo, seen map[string]bool) {
	if ast == nil {
		return
	}

	// Helper to collect params from an expression
	var collectFromExpr func(expr query.Expr)
	collectFromExpr = func(expr query.Expr) {
		if expr == nil {
			return
		}

		switch e := expr.(type) {
		case query.ParamExpr:
			if !seen[e.Name] {
				*params = append(*params, ParamInfo{
					Name:   e.Name,
					GoType: e.GoType,
				})
				seen[e.Name] = true
			}
		case query.BinaryExpr:
			collectFromExpr(e.Left)
			collectFromExpr(e.Right)
		case query.UnaryExpr:
			collectFromExpr(e.Expr)
		case query.FuncExpr:
			for _, arg := range e.Args {
				collectFromExpr(arg)
			}
		case query.ListExpr:
			for _, val := range e.Values {
				collectFromExpr(val)
			}
		case query.AggregateExpr:
			collectFromExpr(e.Arg)
		case query.SubqueryExpr:
			collectFromAST(e.Query, params, seen)
		case query.ExistsExpr:
			collectFromAST(e.Subquery, params, seen)
		}
	}

	// Walk SELECT columns
	for _, sel := range ast.SelectCols {
		collectFromExpr(sel.Expr)
	}

	// Walk joins
	for _, join := range ast.Joins {
		collectFromExpr(join.Condition)
	}

	// Walk WHERE
	collectFromExpr(ast.Where)

	// Walk HAVING
	collectFromExpr(ast.Having)

	// Walk ORDER BY
	for _, ob := range ast.OrderBy {
		collectFromExpr(ob.Expr)
	}

	// Walk LIMIT and OFFSET
	collectFromExpr(ast.Limit)
	collectFromExpr(ast.Offset)

	// Walk INSERT values
	for _, val := range ast.InsertVals {
		collectFromExpr(val)
	}

	// Walk SET clauses
	for _, set := range ast.SetClauses {
		collectFromExpr(set.Value)
	}

	// Walk set operations
	if ast.SetOp != nil {
		collectFromAST(ast.SetOp.Left, params, seen)
		collectFromAST(ast.SetOp.Right, params, seen)
	}

	// Walk CTEs
	for _, cte := range ast.CTEs {
		collectFromAST(cte.Query, params, seen)
	}
}

// =============================================================================
// QueryRunner Generation for User-Defined Queries
// =============================================================================

// DialectSQL holds compiled SQL for each database dialect.
type DialectSQL struct {
	Postgres string
	MySQL    string
	SQLite   string
}

// DialectParamOrder holds the parameter occurrence order for each dialect.
// This includes duplicates - if a param is used twice, it appears twice.
type DialectParamOrder struct {
	Postgres []string
	MySQL    []string
	SQLite   []string
}

// CompiledQueryWithDialects extends CompiledQuery with per-dialect SQL.
type CompiledQueryWithDialects struct {
	CompiledQuery
	SQL DialectSQL
	// ParamOrder holds the parameter names in occurrence order (with duplicates).
	// This is needed because the SQL placeholders ($1, $2 or ?, ?) are per-occurrence,
	// so we need to build args in the same order.
	ParamOrder DialectParamOrder
}

// toLowerCamelCase converts a PascalCase string to lowerCamelCase.
func toLowerCamelCase(s string) string {
	if len(s) == 0 {
		return s
	}
	// Handle consecutive uppercase letters at the start
	for i, r := range s {
		if i == 0 {
			continue
		}
		if r >= 'A' && r <= 'Z' {
			continue
		}
		// Found first lowercase
		if i > 1 {
			// Keep all but last uppercase as lowercase
			return strings.ToLower(s[:i-1]) + s[i-1:]
		}
		return strings.ToLower(s[:1]) + s[1:]
	}
	// All uppercase
	return strings.ToLower(s)
}

// =============================================================================
// Dialect-Specific Runner Generation
// =============================================================================

// GenerateDialectRunner generates a runner.go for a specific dialect (sqlite, postgres, mysql).
// The generated code imports the parent package for shared types.
func GenerateDialectRunner(
	queries []CompiledQueryWithDialects,
	crudPlan *migrate.MigrationPlan,
	dialect string, // "sqlite", "postgres", or "mysql"
	typesImportPath string, // e.g., "myapp/queries"
	tableOpts map[string]CRUDOptions,
) ([]byte, error) {
	var buf bytes.Buffer

	// Sort queries by name for deterministic output
	sort.Slice(queries, func(i, j int) bool {
		return queries[i].Name < queries[j].Name
	})

	// Sort CRUD tables by name
	var tableNames []string
	if crudPlan != nil {
		tableNames = make([]string, 0, len(crudPlan.Schema.Tables))
		for name := range crudPlan.Schema.Tables {
			tableNames = append(tableNames, name)
		}
		sort.Strings(tableNames)
	}

	// Collect imports
	imports := map[string]bool{
		"context":      true,
		"database/sql": true,
	}

	// Always import the parent types package if we have queries or CRUD
	if len(queries) > 0 || len(tableNames) > 0 {
		imports[typesImportPath] = true
	}

	// nanoid is only needed if we have CRUD tables with public_id (for Insert methods)
	for _, tableName := range tableNames {
		table := crudPlan.Schema.Tables[tableName]
		analysis := AnalyzeTable(table)
		if analysis.HasPublicID {
			imports["github.com/portsql/nanoid"] = true
			break
		}
	}

	// Write package and imports
	buf.WriteString("// Code generated by portsql. DO NOT EDIT.\n")
	buf.WriteString(fmt.Sprintf("package %s\n\n", dialect))

	buf.WriteString("import (\n")
	importList := make([]string, 0, len(imports))
	for imp := range imports {
		importList = append(importList, imp)
	}
	sort.Strings(importList)
	for _, imp := range importList {
		buf.WriteString(fmt.Sprintf("\t%q\n", imp))
	}
	buf.WriteString(")\n\n")

	// Write Querier interface
	buf.WriteString("// Querier is the interface for executing queries.\n")
	buf.WriteString("type Querier interface {\n")
	buf.WriteString("\tExecContext(ctx context.Context, query string, args ...any) (sql.Result, error)\n")
	buf.WriteString("\tQueryContext(ctx context.Context, query string, args ...any) (*sql.Rows, error)\n")
	buf.WriteString("\tQueryRowContext(ctx context.Context, query string, args ...any) *sql.Row\n")
	buf.WriteString("}\n\n")

	// Write QueryRunner struct (no dialect field needed!)
	buf.WriteString(fmt.Sprintf("// QueryRunner for %s.\n", dialect))
	buf.WriteString("type QueryRunner struct {\n")
	buf.WriteString("\tdb Querier\n\n")

	// Add SQL string fields for user-defined queries
	if len(queries) > 0 {
		buf.WriteString("\t// User-defined query SQL strings\n")
		for _, q := range queries {
			fieldName := toLowerCamelCase(q.Name) + "SQL"
			buf.WriteString(fmt.Sprintf("\t%s string\n", fieldName))
		}
		buf.WriteString("\n")
	}

	// Add SQL string fields for CRUD
	for _, tableName := range tableNames {
		table := crudPlan.Schema.Tables[tableName]
		analysis := AnalyzeTable(table)
		singular := toSingular(tableName)

		buf.WriteString(fmt.Sprintf("\t// %s CRUD SQL strings\n", toPascalCase(tableName)))
		buf.WriteString(fmt.Sprintf("\tget%sSQL        string\n", toPascalCase(singular)))
		buf.WriteString(fmt.Sprintf("\tlist%sSQL       string\n", toPascalCase(tableName)))
		buf.WriteString(fmt.Sprintf("\tinsert%sSQL     string\n", toPascalCase(singular)))
		buf.WriteString(fmt.Sprintf("\tupdate%sSQL     string\n", toPascalCase(singular)))
		buf.WriteString(fmt.Sprintf("\tdelete%sSQL     string\n", toPascalCase(singular)))
		if analysis.HasDeletedAt {
			buf.WriteString(fmt.Sprintf("\thardDelete%sSQL string\n", toPascalCase(singular)))
		}
		buf.WriteString("\n")
	}
	buf.WriteString("}\n\n")

	// Get the dialect enum for SQL generation
	var dialectEnum SQLDialect
	switch dialect {
	case "postgres":
		dialectEnum = SQLDialectPostgres
	case "mysql":
		dialectEnum = SQLDialectMySQL
	case "sqlite":
		dialectEnum = SQLDialectSQLite
	}

	// Write NewQueryRunner constructor (no dialect parameter!)
	buf.WriteString(fmt.Sprintf("// NewQueryRunner creates a %s query runner.\n", dialect))
	buf.WriteString("func NewQueryRunner(db Querier) *QueryRunner {\n")
	buf.WriteString("\treturn &QueryRunner{\n")
	buf.WriteString("\t\tdb: db,\n")

	// User-defined query SQL
	for _, q := range queries {
		fieldName := toLowerCamelCase(q.Name) + "SQL"
		var sql string
		switch dialectEnum {
		case SQLDialectPostgres:
			sql = q.SQL.Postgres
		case SQLDialectMySQL:
			sql = q.SQL.MySQL
		case SQLDialectSQLite:
			sql = q.SQL.SQLite
		}
		buf.WriteString(fmt.Sprintf("\t\t%s: %q,\n", fieldName, sql))
	}

	// CRUD SQL
	for _, tableName := range tableNames {
		table := crudPlan.Schema.Tables[tableName]
		opts := CRUDOptions{}
		if tableOpts != nil {
			opts = tableOpts[tableName]
		}
		sqlSet := GenerateCRUDSQL(table, dialectEnum, opts)
		analysis := AnalyzeTable(table)
		singular := toSingular(tableName)

		buf.WriteString(fmt.Sprintf("\t\tget%sSQL: %q,\n", toPascalCase(singular), sqlSet.GetSQL))
		buf.WriteString(fmt.Sprintf("\t\tlist%sSQL: %q,\n", toPascalCase(tableName), sqlSet.ListSQL))
		buf.WriteString(fmt.Sprintf("\t\tinsert%sSQL: %q,\n", toPascalCase(singular), sqlSet.InsertSQL))
		buf.WriteString(fmt.Sprintf("\t\tupdate%sSQL: %q,\n", toPascalCase(singular), sqlSet.UpdateSQL))
		buf.WriteString(fmt.Sprintf("\t\tdelete%sSQL: %q,\n", toPascalCase(singular), sqlSet.DeleteSQL))
		if analysis.HasDeletedAt {
			buf.WriteString(fmt.Sprintf("\t\thardDelete%sSQL: %q,\n", toPascalCase(singular), sqlSet.HardDeleteSQL))
		}
	}

	buf.WriteString("\t}\n")
	buf.WriteString("}\n\n")

	// Write WithTx method
	buf.WriteString("// WithTx returns a new QueryRunner using the given transaction.\n")
	buf.WriteString("func (r *QueryRunner) WithTx(tx *sql.Tx) *QueryRunner {\n")
	buf.WriteString("\treturn &QueryRunner{\n")
	buf.WriteString("\t\tdb: tx,\n")

	// Copy user-defined query SQL fields
	for _, q := range queries {
		fieldName := toLowerCamelCase(q.Name) + "SQL"
		buf.WriteString(fmt.Sprintf("\t\t%s: r.%s,\n", fieldName, fieldName))
	}

	// Copy CRUD SQL fields
	for _, tableName := range tableNames {
		table := crudPlan.Schema.Tables[tableName]
		analysis := AnalyzeTable(table)
		singular := toSingular(tableName)

		buf.WriteString(fmt.Sprintf("\t\tget%sSQL: r.get%sSQL,\n", toPascalCase(singular), toPascalCase(singular)))
		buf.WriteString(fmt.Sprintf("\t\tlist%sSQL: r.list%sSQL,\n", toPascalCase(tableName), toPascalCase(tableName)))
		buf.WriteString(fmt.Sprintf("\t\tinsert%sSQL: r.insert%sSQL,\n", toPascalCase(singular), toPascalCase(singular)))
		buf.WriteString(fmt.Sprintf("\t\tupdate%sSQL: r.update%sSQL,\n", toPascalCase(singular), toPascalCase(singular)))
		buf.WriteString(fmt.Sprintf("\t\tdelete%sSQL: r.delete%sSQL,\n", toPascalCase(singular), toPascalCase(singular)))
		if analysis.HasDeletedAt {
			buf.WriteString(fmt.Sprintf("\t\thardDelete%sSQL: r.hardDelete%sSQL,\n", toPascalCase(singular), toPascalCase(singular)))
		}
	}

	buf.WriteString("\t}\n")
	buf.WriteString("}\n\n")

	// Get the types package name (last part of import path)
	typesPkg := "queries"
	if idx := strings.LastIndex(typesImportPath, "/"); idx >= 0 {
		typesPkg = typesImportPath[idx+1:]
	}

	// Generate methods for user-defined queries
	for _, q := range queries {
		generateDialectQueryMethod(&buf, q, dialect, typesPkg)
	}

	// Generate CRUD methods for each table
	for _, tableName := range tableNames {
		table := crudPlan.Schema.Tables[tableName]
		opts := CRUDOptions{}
		if tableOpts != nil {
			opts = tableOpts[tableName]
		}
		generateDialectCRUDMethods(&buf, table, opts, dialect, typesPkg)
	}

	// Format the code
	formatted, err := format.Source(buf.Bytes())
	if err != nil {
		return buf.Bytes(), fmt.Errorf("failed to format generated code: %w", err)
	}

	return formatted, nil
}

// generateDialectQueryMethod generates a query method with dialect-specific scanning.
func generateDialectQueryMethod(buf *bytes.Buffer, q CompiledQueryWithDialects, dialect, typesPkg string) {
	sqlField := toLowerCamelCase(q.Name) + "SQL"

	// Identify JSON columns that need special handling for SQLite
	jsonColumns := make(map[string]bool)
	for _, r := range q.Results {
		if r.GoType == "json.RawMessage" {
			jsonColumns[toPascalCase(r.Name)] = true
		}
	}

	switch q.ReturnType {
	case "one":
		generateDialectOneMethod(buf, q, sqlField, dialect, typesPkg, jsonColumns)
	case "many":
		generateDialectManyMethod(buf, q, sqlField, dialect, typesPkg, jsonColumns)
	case "exec":
		generateDialectExecMethod(buf, q, sqlField, dialect, typesPkg)
	default:
		// Default to many for backward compatibility
		generateDialectManyMethod(buf, q, sqlField, dialect, typesPkg, jsonColumns)
	}
}

// generateDialectOneMethod generates a method that returns 0 or 1 row.
func generateDialectOneMethod(buf *bytes.Buffer, q CompiledQueryWithDialects, sqlField, dialect, typesPkg string, jsonColumns map[string]bool) {
	resultType := fmt.Sprintf("%s.%sResult", typesPkg, q.Name)
	paramsType := fmt.Sprintf("%s.%sParams", typesPkg, q.Name)

	// Get param order for this dialect (includes duplicates)
	paramOrder := getParamOrderForDialect(q, dialect)

	buf.WriteString(fmt.Sprintf("// %s executes the query and returns at most one result.\n", q.Name))

	// Method signature
	if len(q.Params) > 0 {
		buf.WriteString(fmt.Sprintf("func (r *QueryRunner) %s(ctx context.Context, params %s) (*%s, error) {\n",
			q.Name, paramsType, resultType))
	} else {
		buf.WriteString(fmt.Sprintf("func (r *QueryRunner) %s(ctx context.Context) (*%s, error) {\n",
			q.Name, resultType))
	}

	// Build args using param occurrence order (handles duplicates correctly)
	if len(paramOrder) > 0 {
		buf.WriteString("\targs := []any{\n")
		for _, paramName := range paramOrder {
			buf.WriteString(fmt.Sprintf("\t\tparams.%s,\n", toPascalCase(paramName)))
		}
		buf.WriteString("\t}\n\n")
		buf.WriteString(fmt.Sprintf("\trow := r.db.QueryRowContext(ctx, r.%s, args...)\n", sqlField))
	} else {
		buf.WriteString(fmt.Sprintf("\trow := r.db.QueryRowContext(ctx, r.%s)\n", sqlField))
	}

	// Declare result and temp variables for JSON columns
	buf.WriteString(fmt.Sprintf("\n\tvar result %s\n", resultType))

	// For SQLite with JSON columns, we need sql.NullString to handle NULLs
	if dialect == "sqlite" && len(jsonColumns) > 0 {
		for _, res := range q.Results {
			fieldName := toPascalCase(res.Name)
			if jsonColumns[fieldName] {
				buf.WriteString(fmt.Sprintf("\tvar %sNull sql.NullString\n", toLowerCamelCase(res.Name)))
			}
		}
	}

	// Scan
	buf.WriteString("\terr := row.Scan(\n")
	for _, res := range q.Results {
		fieldName := toPascalCase(res.Name)
		if dialect == "sqlite" && jsonColumns[fieldName] {
			// SQLite: scan JSON to sql.NullString temp var
			buf.WriteString(fmt.Sprintf("\t\t&%sNull,\n", toLowerCamelCase(res.Name)))
		} else {
			buf.WriteString(fmt.Sprintf("\t\t&result.%s,\n", fieldName))
		}
	}
	buf.WriteString("\t)\n")
	buf.WriteString("\tif err == sql.ErrNoRows {\n")
	buf.WriteString("\t\treturn nil, nil\n")
	buf.WriteString("\t}\n")
	buf.WriteString("\tif err != nil {\n")
	buf.WriteString("\t\treturn nil, err\n")
	buf.WriteString("\t}\n")

	// For SQLite, convert JSON sql.NullString to []byte (nil if NULL)
	if dialect == "sqlite" && len(jsonColumns) > 0 {
		for _, res := range q.Results {
			fieldName := toPascalCase(res.Name)
			if jsonColumns[fieldName] {
				buf.WriteString(fmt.Sprintf("\tif %sNull.Valid {\n", toLowerCamelCase(res.Name)))
				buf.WriteString(fmt.Sprintf("\t\tresult.%s = []byte(%sNull.String)\n", fieldName, toLowerCamelCase(res.Name)))
				buf.WriteString("\t}\n")
			}
		}
	}

	buf.WriteString("\treturn &result, nil\n")
	buf.WriteString("}\n\n")
}

// generateDialectManyMethod generates a method that returns 0 to N rows.
func generateDialectManyMethod(buf *bytes.Buffer, q CompiledQueryWithDialects, sqlField, dialect, typesPkg string, jsonColumns map[string]bool) {
	resultType := fmt.Sprintf("%s.%sResult", typesPkg, q.Name)
	paramsType := fmt.Sprintf("%s.%sParams", typesPkg, q.Name)

	// Get param order for this dialect (includes duplicates)
	paramOrder := getParamOrderForDialect(q, dialect)

	buf.WriteString(fmt.Sprintf("// %s executes the query and returns all results.\n", q.Name))

	// Method signature
	if len(q.Params) > 0 {
		buf.WriteString(fmt.Sprintf("func (r *QueryRunner) %s(ctx context.Context, params %s) ([]%s, error) {\n",
			q.Name, paramsType, resultType))
	} else {
		buf.WriteString(fmt.Sprintf("func (r *QueryRunner) %s(ctx context.Context) ([]%s, error) {\n",
			q.Name, resultType))
	}

	// Build args using param occurrence order (handles duplicates correctly)
	if len(paramOrder) > 0 {
		buf.WriteString("\targs := []any{\n")
		for _, paramName := range paramOrder {
			buf.WriteString(fmt.Sprintf("\t\tparams.%s,\n", toPascalCase(paramName)))
		}
		buf.WriteString("\t}\n\n")
		buf.WriteString(fmt.Sprintf("\trows, err := r.db.QueryContext(ctx, r.%s, args...)\n", sqlField))
	} else {
		buf.WriteString(fmt.Sprintf("\trows, err := r.db.QueryContext(ctx, r.%s)\n", sqlField))
	}

	buf.WriteString("\tif err != nil {\n")
	buf.WriteString("\t\treturn nil, err\n")
	buf.WriteString("\t}\n")
	buf.WriteString("\tdefer rows.Close()\n\n")

	// Scan results
	buf.WriteString(fmt.Sprintf("\tvar results []%s\n", resultType))
	buf.WriteString("\tfor rows.Next() {\n")
	buf.WriteString(fmt.Sprintf("\t\tvar item %s\n", resultType))

	// For SQLite with JSON columns, we need sql.NullString to handle NULLs
	if dialect == "sqlite" && len(jsonColumns) > 0 {
		for _, res := range q.Results {
			fieldName := toPascalCase(res.Name)
			if jsonColumns[fieldName] {
				buf.WriteString(fmt.Sprintf("\t\tvar %sNull sql.NullString\n", toLowerCamelCase(res.Name)))
			}
		}
	}

	buf.WriteString("\t\terr := rows.Scan(\n")
	for _, res := range q.Results {
		fieldName := toPascalCase(res.Name)
		if dialect == "sqlite" && jsonColumns[fieldName] {
			// SQLite: scan JSON to sql.NullString temp var
			buf.WriteString(fmt.Sprintf("\t\t\t&%sNull,\n", toLowerCamelCase(res.Name)))
		} else {
			buf.WriteString(fmt.Sprintf("\t\t\t&item.%s,\n", fieldName))
		}
	}
	buf.WriteString("\t\t)\n")
	buf.WriteString("\t\tif err != nil {\n")
	buf.WriteString("\t\t\treturn nil, err\n")
	buf.WriteString("\t\t}\n")

	// For SQLite, convert JSON sql.NullString to []byte (nil if NULL)
	if dialect == "sqlite" && len(jsonColumns) > 0 {
		for _, res := range q.Results {
			fieldName := toPascalCase(res.Name)
			if jsonColumns[fieldName] {
				buf.WriteString(fmt.Sprintf("\t\tif %sNull.Valid {\n", toLowerCamelCase(res.Name)))
				buf.WriteString(fmt.Sprintf("\t\t\titem.%s = []byte(%sNull.String)\n", fieldName, toLowerCamelCase(res.Name)))
				buf.WriteString("\t\t}\n")
			}
		}
	}

	buf.WriteString("\t\tresults = append(results, item)\n")
	buf.WriteString("\t}\n\n")

	buf.WriteString("\tif err := rows.Err(); err != nil {\n")
	buf.WriteString("\t\treturn nil, err\n")
	buf.WriteString("\t}\n")
	buf.WriteString("\treturn results, nil\n")
	buf.WriteString("}\n\n")
}

// generateDialectExecMethod generates a method that executes without returning rows.
func generateDialectExecMethod(buf *bytes.Buffer, q CompiledQueryWithDialects, sqlField, dialect, typesPkg string) {
	paramsType := fmt.Sprintf("%s.%sParams", typesPkg, q.Name)

	// Get param order for this dialect (includes duplicates)
	paramOrder := getParamOrderForDialect(q, dialect)

	buf.WriteString(fmt.Sprintf("// %s executes the query and returns the result.\n", q.Name))

	// Method signature
	if len(q.Params) > 0 {
		buf.WriteString(fmt.Sprintf("func (r *QueryRunner) %s(ctx context.Context, params %s) (sql.Result, error) {\n",
			q.Name, paramsType))
	} else {
		buf.WriteString(fmt.Sprintf("func (r *QueryRunner) %s(ctx context.Context) (sql.Result, error) {\n",
			q.Name))
	}

	// Build args using param occurrence order (handles duplicates correctly)
	if len(paramOrder) > 0 {
		buf.WriteString("\targs := []any{\n")
		for _, paramName := range paramOrder {
			buf.WriteString(fmt.Sprintf("\t\tparams.%s,\n", toPascalCase(paramName)))
		}
		buf.WriteString("\t}\n\n")
		buf.WriteString(fmt.Sprintf("\treturn r.db.ExecContext(ctx, r.%s, args...)\n", sqlField))
	} else {
		buf.WriteString(fmt.Sprintf("\treturn r.db.ExecContext(ctx, r.%s)\n", sqlField))
	}

	buf.WriteString("}\n\n")
}

// getParamOrderForDialect returns the parameter occurrence order for a specific dialect.
func getParamOrderForDialect(q CompiledQueryWithDialects, dialect string) []string {
	switch dialect {
	case "postgres":
		return q.ParamOrder.Postgres
	case "mysql":
		return q.ParamOrder.MySQL
	case "sqlite":
		return q.ParamOrder.SQLite
	default:
		// Fallback to postgres order
		return q.ParamOrder.Postgres
	}
}

// generateDialectCRUDMethods generates CRUD methods for a table with dialect-specific scanning.
func generateDialectCRUDMethods(buf *bytes.Buffer, table ddl.Table, opts CRUDOptions, dialect, typesPkg string) {
	analysis := AnalyzeTable(table)
	singular := toSingular(table.Name)
	singularPascal := toPascalCase(singular)
	pluralPascal := toPascalCase(table.Name)

	// Identify JSON columns
	jsonColumns := make(map[string]bool)
	for _, col := range table.Columns {
		mapping := MapColumnType(col)
		if mapping.GoType == "json.RawMessage" {
			jsonColumns[toPascalCase(col.Name)] = true
		}
	}

	// --- Get ---
	generateDialectGetMethod(buf, table, analysis, singularPascal, opts, dialect, typesPkg, jsonColumns)

	// --- List ---
	generateDialectListMethod(buf, table, analysis, singularPascal, pluralPascal, opts, dialect, typesPkg, jsonColumns)

	// --- Insert ---
	generateDialectInsertMethod(buf, table, analysis, singularPascal, opts, dialect, typesPkg)

	// --- Update ---
	generateDialectUpdateMethod(buf, table, analysis, singularPascal, opts, dialect, typesPkg)

	// --- Delete ---
	generateDialectDeleteMethod(buf, table, analysis, singularPascal, opts, dialect, typesPkg)

	// --- HardDelete ---
	if analysis.HasDeletedAt {
		generateDialectHardDeleteMethod(buf, table, analysis, singularPascal, opts, dialect, typesPkg)
	}
}

func generateDialectGetMethod(buf *bytes.Buffer, table ddl.Table, analysis TableAnalysis, singularPascal string, opts CRUDOptions, dialect, typesPkg string, jsonColumns map[string]bool) {
	paramsType := fmt.Sprintf("%s.Get%sParams", typesPkg, singularPascal)
	resultType := fmt.Sprintf("%s.Get%sResult", typesPkg, singularPascal)

	buf.WriteString(fmt.Sprintf("// Get%s fetches a single %s by its identifier.\n", singularPascal, toSingular(table.Name)))
	buf.WriteString(fmt.Sprintf("func (r *QueryRunner) Get%s(ctx context.Context, params %s) (*%s, error) {\n",
		singularPascal, paramsType, resultType))

	// Build args list
	buf.WriteString("\tvar args []any\n")
	if analysis.HasPublicID {
		buf.WriteString("\targs = append(args, params.PublicID)\n")
	} else {
		buf.WriteString("\targs = append(args, params.ID)\n")
	}
	if opts.ScopeColumn != "" {
		buf.WriteString(fmt.Sprintf("\targs = append(args, params.%s)\n", toPascalCase(opts.ScopeColumn)))
	}

	buf.WriteString(fmt.Sprintf("\n\trow := r.db.QueryRowContext(ctx, r.get%sSQL, args...)\n", singularPascal))
	buf.WriteString(fmt.Sprintf("\n\tvar result %s\n", resultType))

	// For SQLite with JSON columns, use sql.NullString to handle NULLs
	if dialect == "sqlite" && len(jsonColumns) > 0 {
		for _, col := range analysis.ResultColumns {
			fieldName := toPascalCase(col.Name)
			if jsonColumns[fieldName] {
				buf.WriteString(fmt.Sprintf("\tvar %sNull sql.NullString\n", toLowerCamelCase(col.Name)))
			}
		}
	}

	buf.WriteString("\terr := row.Scan(\n")

	// Scan result columns
	for _, col := range analysis.ResultColumns {
		fieldName := toPascalCase(col.Name)
		if dialect == "sqlite" && jsonColumns[fieldName] {
			buf.WriteString(fmt.Sprintf("\t\t&%sNull,\n", toLowerCamelCase(col.Name)))
		} else {
			buf.WriteString(fmt.Sprintf("\t\t&result.%s,\n", fieldName))
		}
	}
	buf.WriteString("\t)\n")
	buf.WriteString("\tif err == sql.ErrNoRows {\n")
	buf.WriteString("\t\treturn nil, nil\n")
	buf.WriteString("\t}\n")
	buf.WriteString("\tif err != nil {\n")
	buf.WriteString("\t\treturn nil, err\n")
	buf.WriteString("\t}\n")

	// For SQLite, convert JSON sql.NullString to []byte (nil if NULL)
	if dialect == "sqlite" && len(jsonColumns) > 0 {
		for _, col := range analysis.ResultColumns {
			fieldName := toPascalCase(col.Name)
			if jsonColumns[fieldName] {
				buf.WriteString(fmt.Sprintf("\tif %sNull.Valid {\n", toLowerCamelCase(col.Name)))
				buf.WriteString(fmt.Sprintf("\t\tresult.%s = []byte(%sNull.String)\n", fieldName, toLowerCamelCase(col.Name)))
				buf.WriteString("\t}\n")
			}
		}
	}

	buf.WriteString("\treturn &result, nil\n")
	buf.WriteString("}\n\n")
}

func generateDialectListMethod(buf *bytes.Buffer, table ddl.Table, analysis TableAnalysis, singularPascal, pluralPascal string, opts CRUDOptions, dialect, typesPkg string, jsonColumns map[string]bool) {
	paramsType := fmt.Sprintf("%s.List%sParams", typesPkg, pluralPascal)
	resultType := fmt.Sprintf("%s.List%sResult", typesPkg, pluralPascal)

	buf.WriteString(fmt.Sprintf("// List%s fetches a paginated list of %s.\n", pluralPascal, table.Name))
	buf.WriteString(fmt.Sprintf("func (r *QueryRunner) List%s(ctx context.Context, params %s) ([]%s, error) {\n",
		pluralPascal, paramsType, resultType))

	// Build args list
	buf.WriteString("\tvar args []any\n")
	if opts.ScopeColumn != "" {
		buf.WriteString(fmt.Sprintf("\targs = append(args, params.%s)\n", toPascalCase(opts.ScopeColumn)))
	}
	buf.WriteString("\targs = append(args, params.Limit, params.Offset)\n")

	buf.WriteString(fmt.Sprintf("\n\trows, err := r.db.QueryContext(ctx, r.list%sSQL, args...)\n", pluralPascal))
	buf.WriteString("\tif err != nil {\n")
	buf.WriteString("\t\treturn nil, err\n")
	buf.WriteString("\t}\n")
	buf.WriteString("\tdefer rows.Close()\n")

	buf.WriteString(fmt.Sprintf("\n\tvar results []%s\n", resultType))
	buf.WriteString("\tfor rows.Next() {\n")
	buf.WriteString(fmt.Sprintf("\t\tvar item %s\n", resultType))

	// For SQLite with JSON columns, use sql.NullString to handle NULLs
	if dialect == "sqlite" && len(jsonColumns) > 0 {
		for _, col := range analysis.ResultColumns {
			if col.Name == "updated_at" {
				continue
			}
			fieldName := toPascalCase(col.Name)
			if jsonColumns[fieldName] {
				buf.WriteString(fmt.Sprintf("\t\tvar %sNull sql.NullString\n", toLowerCamelCase(col.Name)))
			}
		}
	}

	buf.WriteString("\t\terr := rows.Scan(\n")

	// Scan result columns (excluding updated_at)
	for _, col := range analysis.ResultColumns {
		if col.Name == "updated_at" {
			continue
		}
		fieldName := toPascalCase(col.Name)
		if dialect == "sqlite" && jsonColumns[fieldName] {
			buf.WriteString(fmt.Sprintf("\t\t\t&%sNull,\n", toLowerCamelCase(col.Name)))
		} else {
			buf.WriteString(fmt.Sprintf("\t\t\t&item.%s,\n", fieldName))
		}
	}
	buf.WriteString("\t\t)\n")
	buf.WriteString("\t\tif err != nil {\n")
	buf.WriteString("\t\t\treturn nil, err\n")
	buf.WriteString("\t\t}\n")

	// For SQLite, convert JSON sql.NullString to []byte (nil if NULL)
	if dialect == "sqlite" && len(jsonColumns) > 0 {
		for _, col := range analysis.ResultColumns {
			if col.Name == "updated_at" {
				continue
			}
			fieldName := toPascalCase(col.Name)
			if jsonColumns[fieldName] {
				buf.WriteString(fmt.Sprintf("\t\tif %sNull.Valid {\n", toLowerCamelCase(col.Name)))
				buf.WriteString(fmt.Sprintf("\t\t\titem.%s = []byte(%sNull.String)\n", fieldName, toLowerCamelCase(col.Name)))
				buf.WriteString("\t\t}\n")
			}
		}
	}

	buf.WriteString("\t\tresults = append(results, item)\n")
	buf.WriteString("\t}\n")

	buf.WriteString("\tif err := rows.Err(); err != nil {\n")
	buf.WriteString("\t\treturn nil, err\n")
	buf.WriteString("\t}\n")
	buf.WriteString("\treturn results, nil\n")
	buf.WriteString("}\n\n")
}

func generateDialectInsertMethod(buf *bytes.Buffer, table ddl.Table, analysis TableAnalysis, singularPascal string, opts CRUDOptions, dialect, typesPkg string) {
	paramsType := fmt.Sprintf("%s.Insert%sParams", typesPkg, singularPascal)

	// Determine return type
	returnType := "error"
	if analysis.HasPublicID {
		returnType = "(string, error)"
	}

	buf.WriteString(fmt.Sprintf("// Insert%s inserts a new %s and returns its public ID.\n", singularPascal, toSingular(table.Name)))
	buf.WriteString(fmt.Sprintf("func (r *QueryRunner) Insert%s(ctx context.Context, params %s) %s {\n",
		singularPascal, paramsType, returnType))

	// Generate public_id if needed
	if analysis.HasPublicID {
		buf.WriteString("\tpublicID := nanoid.New()\n\n")
	}

	// Build args list
	buf.WriteString("\tvar args []any\n")
	if analysis.HasPublicID {
		buf.WriteString("\targs = append(args, publicID)\n")
	}
	if opts.ScopeColumn != "" {
		buf.WriteString(fmt.Sprintf("\targs = append(args, params.%s)\n", toPascalCase(opts.ScopeColumn)))
	}
	for _, col := range analysis.UserColumns {
		if opts.ScopeColumn != "" && col.Name == opts.ScopeColumn {
			continue
		}
		buf.WriteString(fmt.Sprintf("\targs = append(args, params.%s)\n", toPascalCase(col.Name)))
	}

	buf.WriteString("\n")

	if analysis.HasPublicID {
		// Handle dialect-specific RETURNING behavior
		if dialect == "mysql" {
			buf.WriteString(fmt.Sprintf("\t_, err := r.db.ExecContext(ctx, r.insert%sSQL, args...)\n", singularPascal))
			buf.WriteString("\tif err != nil {\n")
			buf.WriteString("\t\treturn \"\", err\n")
			buf.WriteString("\t}\n")
			buf.WriteString("\treturn publicID, nil\n")
		} else {
			// Postgres/SQLite: Use RETURNING
			buf.WriteString("\tvar returnedID string\n")
			buf.WriteString(fmt.Sprintf("\terr := r.db.QueryRowContext(ctx, r.insert%sSQL, args...).Scan(&returnedID)\n", singularPascal))
			buf.WriteString("\tif err != nil {\n")
			buf.WriteString("\t\treturn \"\", err\n")
			buf.WriteString("\t}\n")
			buf.WriteString("\treturn returnedID, nil\n")
		}
	} else {
		buf.WriteString(fmt.Sprintf("\t_, err := r.db.ExecContext(ctx, r.insert%sSQL, args...)\n", singularPascal))
		buf.WriteString("\treturn err\n")
	}

	buf.WriteString("}\n\n")
}

func generateDialectUpdateMethod(buf *bytes.Buffer, table ddl.Table, analysis TableAnalysis, singularPascal string, opts CRUDOptions, dialect, typesPkg string) {
	paramsType := fmt.Sprintf("%s.Update%sParams", typesPkg, singularPascal)

	buf.WriteString(fmt.Sprintf("// Update%s updates an existing %s.\n", singularPascal, toSingular(table.Name)))
	buf.WriteString(fmt.Sprintf("func (r *QueryRunner) Update%s(ctx context.Context, params %s) error {\n",
		singularPascal, paramsType))

	// Build args list: SET values first, then WHERE values
	buf.WriteString("\tvar args []any\n")

	// SET clause args (user columns, excluding scope)
	for _, col := range analysis.UserColumns {
		if opts.ScopeColumn != "" && col.Name == opts.ScopeColumn {
			continue
		}
		buf.WriteString(fmt.Sprintf("\targs = append(args, params.%s)\n", toPascalCase(col.Name)))
	}

	// WHERE clause args
	if analysis.HasPublicID {
		buf.WriteString("\targs = append(args, params.PublicID)\n")
	} else {
		buf.WriteString("\targs = append(args, params.ID)\n")
	}
	if opts.ScopeColumn != "" {
		buf.WriteString(fmt.Sprintf("\targs = append(args, params.%s)\n", toPascalCase(opts.ScopeColumn)))
	}

	buf.WriteString(fmt.Sprintf("\n\t_, err := r.db.ExecContext(ctx, r.update%sSQL, args...)\n", singularPascal))
	buf.WriteString("\treturn err\n")
	buf.WriteString("}\n\n")
}

func generateDialectDeleteMethod(buf *bytes.Buffer, table ddl.Table, analysis TableAnalysis, singularPascal string, opts CRUDOptions, dialect, typesPkg string) {
	paramsType := fmt.Sprintf("%s.Delete%sParams", typesPkg, singularPascal)

	buf.WriteString(fmt.Sprintf("// Delete%s soft-deletes a %s (or hard-deletes if no deleted_at column).\n", singularPascal, toSingular(table.Name)))
	buf.WriteString(fmt.Sprintf("func (r *QueryRunner) Delete%s(ctx context.Context, params %s) error {\n",
		singularPascal, paramsType))

	// Build args list
	buf.WriteString("\tvar args []any\n")
	if analysis.HasPublicID {
		buf.WriteString("\targs = append(args, params.PublicID)\n")
	} else {
		buf.WriteString("\targs = append(args, params.ID)\n")
	}
	if opts.ScopeColumn != "" {
		buf.WriteString(fmt.Sprintf("\targs = append(args, params.%s)\n", toPascalCase(opts.ScopeColumn)))
	}

	buf.WriteString(fmt.Sprintf("\n\t_, err := r.db.ExecContext(ctx, r.delete%sSQL, args...)\n", singularPascal))
	buf.WriteString("\treturn err\n")
	buf.WriteString("}\n\n")
}

func generateDialectHardDeleteMethod(buf *bytes.Buffer, table ddl.Table, analysis TableAnalysis, singularPascal string, opts CRUDOptions, dialect, typesPkg string) {
	paramsType := fmt.Sprintf("%s.HardDelete%sParams", typesPkg, singularPascal)

	buf.WriteString(fmt.Sprintf("// HardDelete%s permanently deletes a %s.\n", singularPascal, toSingular(table.Name)))
	buf.WriteString(fmt.Sprintf("func (r *QueryRunner) HardDelete%s(ctx context.Context, params %s) error {\n",
		singularPascal, paramsType))

	// Build args list
	buf.WriteString("\tvar args []any\n")
	if analysis.HasPublicID {
		buf.WriteString("\targs = append(args, params.PublicID)\n")
	} else {
		buf.WriteString("\targs = append(args, params.ID)\n")
	}
	if opts.ScopeColumn != "" {
		buf.WriteString(fmt.Sprintf("\targs = append(args, params.%s)\n", toPascalCase(opts.ScopeColumn)))
	}

	buf.WriteString(fmt.Sprintf("\n\t_, err := r.db.ExecContext(ctx, r.hardDelete%sSQL, args...)\n", singularPascal))
	buf.WriteString("\treturn err\n")
	buf.WriteString("}\n\n")
}
